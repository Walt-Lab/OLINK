{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Wyss User\\anaconda3\\lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 16:29:31,748 | INFO : Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2024-02-14 16:29:31,750 | INFO : NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\n",
    "    \"C:\\\\Users\\\\Wyss User\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python311\\\\site-packages\"\n",
    ")\n",
    "\n",
    "import biolib\n",
    "import gzip\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "import pathlib\n",
    "import tspex\n",
    "\n",
    "import matplotlib as mat\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests as r\n",
    "import seaborn as sns\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from io import StringIO\n",
    "from matplotlib_venn import venn2\n",
    "from matplotlib_venn import venn3\n",
    "from scipy.integrate import simps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_rna_seq_path = \"C:\\\\Users\\\\Wyss User\\\\Documents\\\\EVs\\\\OLINK\\\\fe-wp-dataset-124.csv\"\n",
    "ht_raw_data = \"C:\\\\Users\\\\Wyss User\\\\Documents\\\\EVs\\\\OLINK\\\\LCSET-29370_AShah_MNorman_Extended_NPX_2024-02-14.parquet\"\n",
    "explore_raw_data = \"C:\\\\Users\\\\Wyss User\\\\Documents\\\\EVs\\\\OLINK\\\\LCSET_28343_10-4-2023_EXTENDED_NPX_2023-10-20.csv\"\n",
    "uniprot_fasta_database = \"C:\\\\Users\\\\Wyss User\\\\Documents\\\\EVs\\\\OLINK\\\\uniprot_fasta_database.gz\"\n",
    "plate_layout_path = \"C:\\\\Users\\\\Wyss User\\\\Documents\\\\EVs\\\\OLINK\\\\Plate Layout.xlsx\"\n",
    "assay_list_path = \"C:\\\\Users\\\\Wyss User\\\\Documents\\\\EVs\\\\OLINK\\\\ht_panel_assay_list.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wyss User\\AppData\\Local\\Temp\\ipykernel_9616\\1030213757.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unique_data.loc[:, \"Linear NPX\"] = unique_data[\"PCNormalizedNPX\"].map(lambda x: 2**x)\n"
     ]
    }
   ],
   "source": [
    "def clean_strings(strings):\n",
    "    cleaned_strings = []\n",
    "    for string in strings:\n",
    "        cleaned_string = str(string).replace(\"(\", \"\").replace(\")\", \"\").replace(\"'\", \"\").replace(\",\", \"\")\n",
    "        cleaned_strings.append(cleaned_string)\n",
    "    return cleaned_strings\n",
    "\n",
    "def clean_up_raw_ht_file(ht_raw_data, plate_layout_path):\n",
    "    ht_data = pd.read_parquet(ht_raw_data)\n",
    "    plate_layout = pd.read_excel(plate_layout_path)\n",
    "    data = pd.merge(ht_data, plate_layout, how=\"left\", on=\"SampleID\")\n",
    "    # repeat assays: P32455, Q02750  \n",
    "    replicate_assays = data[[\"UniProt\"]].value_counts()\n",
    "    replicate_assays = replicate_assays[replicate_assays > 94]\n",
    "    replicate_assay_list = clean_strings(replicate_assays.index.tolist())\n",
    "    unique_data = data[~data[\"UniProt\"].isin(replicate_assay_list)]\n",
    "    unique_data.loc[:, \"Linear NPX\"] = unique_data[\"PCNormalizedNPX\"].map(lambda x: 2**x)\n",
    "    tidy_ht_data = unique_data[unique_data[\"SampleType\"] == \"SAMPLE\"].pivot(\n",
    "        columns = \"UniProt\", index = [\"SampleID\", \"Health\", \"Sample\", \"CSF_sample\"], values = \"Linear NPX\"\n",
    "    )\n",
    "    return tidy_ht_data\n",
    "\n",
    "def clean_up_raw_explore_file(explore_raw_data, plate_layout_path):\n",
    "    panels = [\n",
    "        \"Cardiometabolic\",\n",
    "        \"Cardiometabolic_II\",\n",
    "        \"Inflammation\",\n",
    "        \"Inflammation_II\",\n",
    "        \"Neurology\",\n",
    "        \"Neurology_II\",\n",
    "        \"Oncology\",\n",
    "        \"Oncology_II\",\n",
    "    ]\n",
    "    raw_data = pd.read_csv(explore_raw_data, sep=\";\")\n",
    "    plate_layout = pd.read_excel(plate_layout_path)\n",
    "    data = pd.merge(raw_data, plate_layout, how=\"left\", on=\"SampleID\")\n",
    "    ctrl_dict = {}\n",
    "    for panel in panels:\n",
    "        df = data[(data[\"Panel\"] == panel)]\n",
    "        plate_ctrl = df[\n",
    "            (df[\"Sample_Type\"] == \"PLATE_CONTROL\")\n",
    "            & (df[\"Assay\"] == \"Amplification control 1\")\n",
    "        ][\"NPX\"].median()\n",
    "        ctrl_dict[panel] = plate_ctrl\n",
    "    data[\"Delta\"] = data.apply(\n",
    "        lambda row: row[\"NPX\"] - ctrl_dict[row[\"Panel\"]],\n",
    "        axis=1,\n",
    "    )\n",
    "    for index, row in data.iterrows():\n",
    "        if row[\"Delta\"] < row[\"LOD\"]:\n",
    "            data.at[index, \"NPX\"] = row[\"LOD\"]\n",
    "    data[\"Linear Delta\"] = data[\"Delta\"].map(lambda x: 2**x)\n",
    "    vc = data[[\"SampleID\", \"Sample_Type\", \"UniProt\"]].value_counts()\n",
    "    vc = vc[vc > 1]\n",
    "    unique_uniprot_values = vc.index.get_level_values(\"UniProt\").unique()\n",
    "    uniprot_list = unique_uniprot_values.tolist()\n",
    "    raw_data_no_reps = data[~data[\"UniProt\"].isin(uniprot_list)].copy()\n",
    "    tidy_explore_data = raw_data_no_reps[raw_data_no_reps[\"Sample_Type\"] == \"SAMPLE\"].pivot(\n",
    "        columns=\"UniProt\", index=[\"SampleID\", \"Health\", \"Sample\", \"CSF_sample\"], values=\"Linear Delta\"\n",
    "    )\n",
    "    return tidy_explore_data\n",
    "\n",
    "tidy_ht_data = clean_up_raw_ht_file(ht_raw_data, plate_layout_path)\n",
    "tidy_explore_data = clean_up_raw_explore_file(explore_raw_data, plate_layout_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CSF1', 'CSF CSF A Internal EV', 'CSF2', 'CSF CSF B Internal EV',\n",
       "       'CSF3', 'CSF CSF C Internal EV', 'CSF4', 'CSF D Internal EV', 'CSF5',\n",
       "       'CSF6', 'CSF7', 'CSF8'],\n",
       "      dtype='object', name='CSF_sample')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tidy_ht_data.index.get_level_values(\"CSF_sample\").unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ratio(df):\n",
    "    peaking_fracts = df[((df.index.get_level_values(\"Sample\").str.contains(\"9\")) | (df.index.get_level_values(\"Sample\").str.contains(\"10\"))) & (df.index.get_level_values(\"Health\") == \"Healthy\")].median()\n",
    "    low_fracts = df[((df.index.get_level_values(\"Sample\").str.contains(\"7\")) | (df.index.get_level_values(\"Sample\").str.contains(\"11\")) | (df.index.get_level_values(\"Sample\").str.contains(\"12\")) | (df.index.get_level_values(\"Sample\").str.contains(\"13\"))) & (df.index.get_level_values(\"Health\") == \"Healthy\")].median()\n",
    "    return peaking_fracts / low_fracts\n",
    "\n",
    "def calculate_mean_std_cv(row):\n",
    "    row['mean'] = row[['explore_ratio', 'ht_ratio']].mean()\n",
    "    row['std'] = row[['explore_ratio', 'ht_ratio']].std()\n",
    "    row['cv'] = (row['std'] / row['mean']) * 100 if row['mean'] != 0 else float('NaN')\n",
    "    return row\n",
    "\n",
    "ht_assay = []\n",
    "ht_ratio = []\n",
    "\n",
    "for assay in tidy_ht_data.columns:\n",
    "    df = tidy_ht_data[(tidy_ht_data.index.get_level_values(\"Health\") == \"Healthy\") & ~(tidy_ht_data.index.get_level_values(\"CSF_sample\").str.contains(\"Internal\"))][assay]\n",
    "    ratio = find_ratio(df)\n",
    "    ht_assay.append(assay)\n",
    "    ht_ratio.append(ratio)\n",
    "\n",
    "explore_assay = []\n",
    "explore_ratio = []\n",
    "\n",
    "for assay in tidy_explore_data.columns: \n",
    "    df = tidy_explore_data[(tidy_explore_data.index.get_level_values(\"Health\") == \"Healthy\") & ~(tidy_explore_data.index.get_level_values(\"CSF_sample\").str.contains(\"Internal\"))][assay]\n",
    "    ratio = find_ratio(df)\n",
    "    explore_assay.append(assay)\n",
    "    explore_ratio.append(ratio)\n",
    "\n",
    "ht_fractionation = pd.DataFrame({\"ht_assay\": ht_assay, \"ht_ratio\": ht_ratio})\n",
    "explore_fractionation = pd.DataFrame({\"explore_assay\": explore_assay, \"explore_ratio\": explore_ratio})\n",
    "\n",
    "ht_fractionation_filtered = ht_fractionation[ht_fractionation[\"ht_assay\"].isin(explore_fractionation[\"explore_assay\"])]\n",
    "explore_fractionation_filtered = explore_fractionation[explore_fractionation[\"explore_assay\"].isin(ht_fractionation[\"ht_assay\"])]\n",
    "olink_fractionation = pd.merge(explore_fractionation_filtered, ht_fractionation_filtered, left_on = \"explore_assay\", right_on = \"ht_assay\", how =\"left\")\n",
    "olink_fractionation = olink_fractionation.set_index(\"ht_assay\")\n",
    "olink_fractionation.drop(\"explore_assay\", axis = 1, inplace = True)\n",
    "\n",
    "olink_fractionation = olink_fractionation.apply(calculate_mean_std_cv, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean(df):\n",
    "    \"\"\"\n",
    "    Calculates the mean of all numeric values in a row of a dataframe, and assigns to a new column called \"Mean\".\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pandas.DataFrame\n",
    "        Dataframe with columns containing numeric values.\n",
    "    \"\"\"\n",
    "    return df.assign(Mean=df.mean(axis=1, numeric_only=True))\n",
    "\n",
    "\n",
    "def map_hgnc_ids(brain_rna_seq_path):\n",
    "    \"\"\"\n",
    "    Maps the HGNC IDs in the Brain RNA-Seq file to UniProt IDs.\n",
    "    Parameters\n",
    "    ----------\n",
    "    brain_rna_seq_path: csv file path\n",
    "        Path to the \"homo sapiens.csv\" file, downloaded from brainrnaseq.org.\n",
    "    \"\"\"\n",
    "    hgnc_ids = (\n",
    "        \"https://ftp.ebi.ac.uk/pub/databases/genenames/hgnc/tsv/hgnc_complete_set.txt\"\n",
    "    )\n",
    "    brain_rna_seq = pd.read_csv(brain_rna_seq_path)\n",
    "\n",
    "    hgnc_uniprot_mapping_data = pd.read_csv(\n",
    "        (StringIO(requests.get(hgnc_ids).text)),\n",
    "        sep=\"\\t\",\n",
    "        usecols=[\"hgnc_id\", \"uniprot_ids\"],\n",
    "    )\n",
    "\n",
    "    hgnc_uniprot_mapping_data['uniprot_ids'] = hgnc_uniprot_mapping_data['uniprot_ids'].str.split('|')\n",
    "    hgnc_uniprot_mapping_data = hgnc_uniprot_mapping_data.explode('uniprot_ids')\n",
    "    hgnc_uniprot_mapping_data = hgnc_uniprot_mapping_data.reset_index(drop=True)\n",
    "\n",
    "    brain_rna_seq = pd.merge(\n",
    "        brain_rna_seq,\n",
    "        hgnc_uniprot_mapping_data,\n",
    "        left_on=\"id\",\n",
    "        right_on=\"hgnc_id\",\n",
    "        how=\"inner\",\n",
    "    )\n",
    "    brain_rna_seq.dropna(subset=[\"uniprot_ids\"], inplace=True)\n",
    "    brain_rna_seq.drop_duplicates(subset=[\"uniprot_ids\"], inplace=True)\n",
    "\n",
    "    return brain_rna_seq\n",
    "\n",
    "def mean_cell_type(brain_rna_seq_data, cell_type):\n",
    "    \"\"\"\n",
    "    Returns only the mean of the data for the specified cell type, as well as the UniProt ID information in an additional column\n",
    "    Parameters\n",
    "    ----------\n",
    "    brain_rna_seq_data : pandas.DataFrame\n",
    "        Dataframe with a column called \"uniprot_ids\" (contains UniProt ID), and other columns containing cell-type specific Brain RNA Seq data\n",
    "    cell_type : {'astrocyte', 'endothelial', 'microglia', 'oligodendrocyte', 'neuron'}\n",
    "        Cell type of interest requested. Options:\n",
    "         - 'astrocyte': mature astrocytes\n",
    "         - 'endothelial': endothelial cells\n",
    "         - 'microglia': microglia cells\n",
    "         - 'oligodendrocyte': oligodendrocytes\n",
    "         - 'neuron': neurons\n",
    "    \"\"\"\n",
    "    if cell_type == \"microglia\":\n",
    "        microglia_df = calculate_mean(\n",
    "            brain_rna_seq_data[\n",
    "                brain_rna_seq_data.filter(like=\"microglla\").columns.append(\n",
    "                    pd.Index([\"uniprot_ids\"])\n",
    "                )\n",
    "            ]\n",
    "        )[[\"uniprot_ids\", \"Mean\"]]\n",
    "        return microglia_df.rename(\n",
    "            columns={\"uniprot_ids\": \"uniprot_ids\", \"Mean\": \"microglia\"}\n",
    "        )\n",
    "    if cell_type == \"astrocyte\":\n",
    "        astrocyte_df = calculate_mean(\n",
    "            brain_rna_seq_data[\n",
    "                brain_rna_seq_data.filter(like=\"mature\").columns.append(\n",
    "                    pd.Index([\"uniprot_ids\"])\n",
    "                )\n",
    "            ]\n",
    "        )[[\"uniprot_ids\", \"Mean\"]]\n",
    "        return astrocyte_df.rename(\n",
    "            columns={\"uniprot_ids\": \"uniprot_ids\", \"Mean\": \"astrocyte\"}\n",
    "        )\n",
    "    else:\n",
    "        cell_type_df = calculate_mean(\n",
    "            brain_rna_seq_data[\n",
    "                brain_rna_seq_data.filter(like=cell_type).columns.append(\n",
    "                    pd.Index([\"uniprot_ids\"])\n",
    "                )\n",
    "            ]\n",
    "        )[[\"uniprot_ids\", \"Mean\"]]\n",
    "        return cell_type_df.rename(\n",
    "            columns={\"uniprot_ids\": \"uniprot_ids\", \"Mean\": cell_type}\n",
    "        )\n",
    "    # make this into a dictionary like astrocyte : mature and then iterate over it\n",
    "def calculate_enrichment(row, specificity_metric): \n",
    "    \"\"\"\n",
    "    Uses the numeric values in a row of a dataframe (with the row being expression data for a specific gene of interest) to determine a gene's specificity Returns a numpy array with an index of indentifier for the gene and values of specificity scores.\n",
    "    Parameters\n",
    "    ----------\n",
    "    'row' : pandas.DataFrame\n",
    "        Row of a DataFrame containing expression data for a gene of interest with one column for each cell type/tissue being analyzed. Index should be identifier for each gene.\n",
    "    'specificity_metric' : {'tau', 'tsi', 'gini', 'hg', 'spm', 'zscore'}\n",
    "        Method to determine specificity requested. Options:\n",
    "            - tau: Tau specificity score\n",
    "            - tsi: Tissue Specificity Index\n",
    "            - gini: Gini coefficient\n",
    "            - hg: Entropy of a gene's expression distribution\n",
    "            - spm: Specificity Metric\n",
    "            - zscore: Z-score\n",
    "    References\n",
    "    ----------\n",
    "    Kryuchkova-Mostacci N, Robinson-Rechavi M. A benchmark of gene expression tissue-specificity metrics. Brief Bioinform. 2017 Mar 1;18(2):205-214. doi: 10.1093/bib/bbw008. PMID: 26891983; PMCID: PMC5444245.\n",
    "    Schug J, Schuller WP, Kappen C, Salbaum JM, Bucan M, Stoeckert CJ Jr. Promoter features related to tissue specificity as measured by Shannon entropy. Genome Biol. 2005;6(4):R33. doi: 10.1186/gb-2005-6-4-r33. Epub 2005 Mar 29. PMID: 15833120; PMCID: PMC1088961.\n",
    "    Wright Muelas, M., Mughal, F., O’Hagan, S. et al. The role and robustness of the Gini coefficient as an unbiased tool for the selection of Gini genes for normalising expression profiling data. Sci Rep 9, 17960 (2019). https://doi.org/10.1038/s41598-019-54288-7.\n",
    "    \"\"\"\n",
    "    row_array = np.array(row)\n",
    "    if specificity_metric == \"tau\":\n",
    "        row_x = (row_array/ max(row_array))\n",
    "        return ((np.sum(1 - row_x) / ((len(row_x)) - 1)))\n",
    "    if specificity_metric == \"tsi\":\n",
    "        row_array = np.array(row, dtype=np.float64)\n",
    "        return (max(row_array)/sum(row_array))\n",
    "    if specificity_metric == \"gini\":\n",
    "        row_array = np.array(row, dtype = np.float64)\n",
    "        sorted_types = np.sort(row_array)\n",
    "        cumulative_fraction_types = np.cumsum(sorted_types) / np.sum(sorted_types)\n",
    "        cumulative_fraction_total = np.linspace(0, 1, len(sorted_types))\n",
    "        area_under_line_of_perfect_equality = simps(cumulative_fraction_total, cumulative_fraction_total)\n",
    "        area_under_lorenz_curve = simps(cumulative_fraction_types, cumulative_fraction_total) \n",
    "        return area_under_line_of_perfect_equality / (area_under_line_of_perfect_equality + area_under_lorenz_curve)\n",
    "    if specificity_metric == \"hg\":\n",
    "        row_sum = np.sum(row_array)\n",
    "        p_sub_i = row_array / row_sum\n",
    "        return -1 * (sum(p_sub_i * np.log2(p_sub_i)))\n",
    "    if specificity_metric == \"spm\":\n",
    "        squared_array = row_array ** 2\n",
    "        sum_squared_array = np.sum(squared_array)\n",
    "        spm_score = squared_array / sum_squared_array\n",
    "        return pd.Series(spm_score, index = row.index)\n",
    "    if specificity_metric == \"zscore\":\n",
    "        mean_array = np.mean(row_array)\n",
    "        std_array = np.std(row_array)\n",
    "        zscore_values = (row_array - mean_array) / std_array\n",
    "        return pd.Series(zscore_values, index = row.index)\n",
    "\n",
    "\n",
    "def cell_type_enrichment(\n",
    "    brain_rna_seq_data,\n",
    "    cell_type,\n",
    "    specificity_metric,\n",
    "    specificity_cutoff,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns a list of UniProt IDs corresponding to targets that meet specified criteria to determine cell-type specificity.\n",
    "    Parameters\n",
    "    ----------\n",
    "    'brain_rna_seq_data' : pandas.DataFrame\n",
    "        Dataframe with a column called \"uniprot_ids\" (contains UniProt ID), and other columns containing cell-type specific Brain RNA Seq data for the cell types listed under cell_type\n",
    "    'cell_type' : {'astrocyte', 'endothelial', 'microglia', 'oligodendrocyte', 'neuron'}\n",
    "        Cell type of interest requested. Options:\n",
    "         - 'astrocyte': mature astrocytes\n",
    "         - 'endothelial': endothelial cells\n",
    "         - 'microglia': microglia cells\n",
    "         - 'oligodendrocyte': oligodendrocytes\n",
    "         - 'neuron': neurons\n",
    "    'specificity_metric': {'tsi', 'zscore', 'spm', 'tau', 'gini', 'hg'}\n",
    "        Individualized metric of determining cell type specificity requested. Options:\n",
    "        - 'tsi': tissue specificity index\n",
    "        - 'zscore': z-score\n",
    "        - 'spm': specificity measure\n",
    "        - 'tau': tau index\n",
    "        - 'gini' : gini coefficient\n",
    "        - 'hg' : entropy of a gene's expression distribution\n",
    "    'specificity_cutoff' : numeric\n",
    "        Numeric value representing the minimum value of the second enrichment cutoff.\n",
    "    References\n",
    "    ----------\n",
    "    Kryuchkova-Mostacci N, Robinson-Rechavi M. A benchmark of gene expression tissue-specificity metrics. Brief Bioinform. 2017 Mar 1;18(2):205-214. doi: 10.1093/bib/bbw008. PMID: 26891983; PMCID: PMC5444245.\n",
    "    Schug J, Schuller WP, Kappen C, Salbaum JM, Bucan M, Stoeckert CJ Jr. Promoter features related to tissue specificity as measured by Shannon entropy. Genome Biol. 2005;6(4):R33. doi: 10.1186/gb-2005-6-4-r33. Epub 2005 Mar 29. PMID: 15833120; PMCID: PMC1088961.\n",
    "    Wright Muelas, M., Mughal, F., O’Hagan, S. et al. The role and robustness of the Gini coefficient as an unbiased tool for the selection of Gini genes for normalising expression profiling data. Sci Rep 9, 17960 (2019). https://doi.org/10.1038/s41598-019-54288-7.\n",
    "    \"\"\"\n",
    "\n",
    "    astrocytes = mean_cell_type(brain_rna_seq_data, \"astrocyte\")\n",
    "    endothelial = mean_cell_type(brain_rna_seq_data, \"endothelial\")\n",
    "    microglia = mean_cell_type(brain_rna_seq_data, \"microglia\")\n",
    "    oligodendrocytes = mean_cell_type(brain_rna_seq_data, \"oligodendrocyte\")\n",
    "    neurons = mean_cell_type(brain_rna_seq_data, \"neuron\")\n",
    "\n",
    "    astrocytes = astrocytes[~astrocytes['uniprot_ids'].isna()]\n",
    "    endothelial = endothelial[~endothelial['uniprot_ids'].isna()]\n",
    "    microglia = microglia[~microglia['uniprot_ids'].isna()]\n",
    "    oligodendrocytes = oligodendrocytes[~oligodendrocytes['uniprot_ids'].isna()]\n",
    "    neurons = neurons[~neurons['uniprot_ids'].isna()]\n",
    "\n",
    "    all_cell_types = pd.merge(\n",
    "        pd.merge(\n",
    "            pd.merge(\n",
    "                pd.merge(astrocytes, endothelial, on=\"uniprot_ids\"),\n",
    "                microglia,\n",
    "                on=\"uniprot_ids\",\n",
    "            ),\n",
    "            oligodendrocytes,\n",
    "            on=\"uniprot_ids\",\n",
    "        ),\n",
    "        neurons,\n",
    "        on=\"uniprot_ids\",\n",
    "    )\n",
    "    all_cell_types.set_index(\"uniprot_ids\", inplace=True)\n",
    "\n",
    "    cell_type_uniprot_ids = []\n",
    "\n",
    "    if specificity_metric == \"enrichment\":\n",
    "        if cell_type != \"all\":\n",
    "            other_cell_types = all_cell_types.drop(cell_type, axis = 1)\n",
    "            cell_type_targets = all_cell_types[[cell_type]]\n",
    "            cell_type_targets['comparison'] = other_cell_types.apply(lambda row: row.max(), axis=1)\n",
    "            for index, row in cell_type_targets.iterrows():\n",
    "                cell_type_uniprot_ids.append(row[(row[cell_type]) > (row[\"comparison\"] * specificity_cutoff)].index)\n",
    "        if cell_type == \"all\":\n",
    "            general_targets = all_cell_types[\n",
    "                (all_cell_types[\"neuron\"] < (specificity_cutoff * all_cell_types[\"microglia\"]))\n",
    "                & (all_cell_types[\"neuron\"] < (specificity_cutoff * all_cell_types[\"endothelial\"]))\n",
    "                & (all_cell_types[\"neuron\"] < (specificity_cutoff * all_cell_types[\"oligodendrocyte\"]))\n",
    "                & (all_cell_types[\"neuron\"] < (specificity_cutoff * all_cell_types[\"astrocyte\"]))\n",
    "                & (all_cell_types[\"astrocyte\"] < (specificity_cutoff * all_cell_types[\"microglia\"]))\n",
    "                & (all_cell_types[\"astrocyte\"] < (specificity_cutoff * all_cell_types[\"endothelial\"]))\n",
    "                & (all_cell_types[\"astrocyte\"] < (specificity_cutoff * all_cell_types[\"oligodendrocyte\"]))\n",
    "                & (all_cell_types[\"astrocyte\"] < (specificity_cutoff * all_cell_types[\"neuron\"]))\n",
    "                & (all_cell_types[\"oligodendrocyte\"] < (specificity_cutoff * all_cell_types[\"microglia\"]))\n",
    "                & (all_cell_types[\"oligodendrocyte\"] < (specificity_cutoff * all_cell_types[\"endothelial\"]))\n",
    "                & (all_cell_types[\"oligodendrocyte\"] < (specificity_cutoff * all_cell_types[\"astrocyte\"]))\n",
    "                & (all_cell_types[\"oligodendrocyte\"] < (specificity_cutoff * all_cell_types[\"neuron\"]))\n",
    "                & (all_cell_types[\"microglia\"] < (specificity_cutoff * all_cell_types[\"oligodendrocyte\"]))\n",
    "                & (all_cell_types[\"microglia\"] < (specificity_cutoff * all_cell_types[\"endothelial\"]))\n",
    "                & (all_cell_types[\"microglia\"] < (specificity_cutoff * all_cell_types[\"astrocyte\"]))\n",
    "                & (all_cell_types[\"microglia\"] < (specificity_cutoff * all_cell_types[\"neuron\"]))\n",
    "            ]\n",
    "            cell_type_uniprot_ids = list(general_targets.index)\n",
    "    else:\n",
    "        enrichment_values = all_cell_types.apply(lambda row: calculate_enrichment(row, specificity_metric), axis = 1)\n",
    "        if cell_type != \"all\":\n",
    "            if specificity_metric == \"zscore\" or specificity_metric == \"spm\":\n",
    "                cell_type_uniprot_ids = enrichment_values[(enrichment_values[cell_type]) > (specificity_cutoff)].index.tolist()\n",
    "            if specificity_metric == \"tau\" or specificity_metric == \"gini\" or specificity_metric == \"hg\" or specificity_metric == \"tsi\": \n",
    "                cell_type_uniprots = enrichment_values[enrichment_values > specificity_cutoff].index.tolist()\n",
    "                cell_type_df = all_cell_types.loc[cell_type_uniprots]\n",
    "                for index, row in cell_type_df.iterrows():\n",
    "                    max_column = row.idxmax()\n",
    "                    if max_column == cell_type:\n",
    "                        cell_type_uniprot_ids.append(index)\n",
    "\n",
    "        if cell_type == \"all\":\n",
    "            if specificity_metric == \"tau\" or \"gini\" or \"hg\" or \"tsi\": \n",
    "                df = enrichment_values[enrichment_values < specificity_cutoff].index.tolist()\n",
    "            else:\n",
    "                for index, row in enrichment_values.iterrows():\n",
    "                    cell_type_uniprot_ids = enrichment_values[(enrichment_values[cell_type]) > (specificity_cutoff)].index.tolist()\n",
    "\n",
    "    return cell_type_uniprot_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_fractionation(tidy_dataframe, high_fractions, low_fractions, sample_health = \"all\", mean_median_individual = \"individual\"):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    'tidy_dataframe' : pandas.DataFrame\n",
    "        DataFrame with one column for each assay, one row for each sample, linearized NPX as the vlaues, and the following indices:\n",
    "            - 'SampleID'\n",
    "            - 'Health'\n",
    "            - 'Sample'\n",
    "            - 'CSF_sample'\n",
    "    'high_fractions' : list of strings\n",
    "        Fractions that should be higher than the fractions in the list of low fractions.\n",
    "    'low_fractions' : list of strings\n",
    "        Fractions that should be lower than the fractions in the list of high fractions.\n",
    "    'sample_health' : {'all', 'ad', 'mci', 'mci_spectrum'}\n",
    "        Health of the sample requested. Options: \n",
    "            - 'healthy': only samples from healthy individuals\n",
    "            - 'all': all different health groups\n",
    "            - 'ad': samples from individuals diagnosed with Alzheimer's Disease (AD)\n",
    "            - 'mci': samples from individuals diagnosed with mild cognitive imapirment that has not yet progressed to AD\n",
    "            - 'mci_spectrum': samples from individuals diagnosed with mild cognitive impairment and samples from individuals that have been diagnosed with AD\n",
    "    'mean_median_individual' : {'mean', 'median', 'individual', 'individual_median', 'individual_mean'}\n",
    "        How the groups of samples should be analyzed. Options: \n",
    "            - 'mean': the means of each fraction should be compared against each other\n",
    "            - 'median': the medians of each fraction should be compared against each other\n",
    "            - 'individual': the fractions of each sample should be compared against each other with no aggregation/grouping \n",
    "            - 'individual_median': for each fraction, the median value of all samples will be compared\n",
    "            - 'individual_mean': for each fraction, the mean value of all samples will be compared\n",
    "        Default value: 'individual'\n",
    "    \"\"\"\n",
    "    \n",
    "    non_ppa_data = tidy_dataframe[tidy_dataframe.index.get_level_values(\"Sample\").str.contains(\"SEC\")]\n",
    "    if sample_health == 'healthy': \n",
    "        requested_health_data = non_ppa_data[non_ppa_data.index.get_level_values(\"Health\").str.contains('Healthy')]\n",
    "    if sample_health == 'all': \n",
    "        requested_health_data = non_ppa_data\n",
    "    if sample_health == 'ad': \n",
    "        requested_health_data =  non_ppa_data[non_ppa_dat.index.get_level_values(\"Health\").str.contains('AD')]\n",
    "    if sample_health == 'mci':\n",
    "        requested_health_data =  non_ppa_data[non_ppa_data.index.get_level_values(\"Health\").str.contains('MCI')]\n",
    "    if sample_health == 'mci_spectrum': \n",
    "        requested_health_data = non_ppa_data[\n",
    "            (non_ppa_data.index.get_level_values(\"Health\").str.contains('AD'))\n",
    "            | (non_ppa_data.index.get_level_values('Health').str.contains('MCI'))\n",
    "        ]\n",
    "\n",
    "    high_fractions_dataframes = {}\n",
    "    for fraction in high_fractions:\n",
    "        high_fractions_dataframes[fraction] = requested_health_data[requested_health_data.index.get_level_values(\"Sample\").str.contains(fraction)]\n",
    "    high_fractions_df = pd.concat(high_fractions_dataframes.values(), axis = 0)\n",
    "    low_fractions_dataframes = {}\n",
    "    for fraction in low_fractions: \n",
    "        low_fractions_dataframes[fraction] = requested_health_data[requested_health_data.index.get_level_values(\"Sample\").str.contains(fraction)]\n",
    "    low_fractions_df = pd.concat(low_fractions_dataframes.values(), axis=0)\n",
    "\n",
    "    correct_fractionation = []\n",
    "  \n",
    "    for assay in list(non_ppa_data.columns):\n",
    "        if mean_median_individual == \"median\":\n",
    "            if not high_fractions_df[assay].isna().all():\n",
    "                high_fractions = high_fractions_df[assay].median()\n",
    "\n",
    "            if not low_fractions_df[assay].isna().all():\n",
    "                low_fractions = low_fractions_df[assay].median()\n",
    "            if high_fractions > low_fractions: \n",
    "                correct_fractionation.append(assay)\n",
    "        if mean_median_individual == \"mean\":\n",
    "            if not high_fractions_df[assay].isna().all():\n",
    "                high_fractions = high_fractions_df[assay].mean()\n",
    "            if not low_fractions_df[assay].isna().all():\n",
    "                low_fractions = low_fractions_df[assay].mean()\n",
    "            if high_fractions > low_fractions: \n",
    "                correct_fractionation.append(assay)\n",
    "        if mean_median_individual == \"individual\":\n",
    "            for sample in list(requested_health_data.index.get_level_values(\"CSF_sample\").unique()):\n",
    "                high_sample_data = high_fractions_df[high_fractions_df.index.get_level_values(\"CSF_sample\") == sample][assay].tolist()\n",
    "                low_sample_data = low_fractions_df[low_fractions_df.index.get_level_values(\"CSF_sample\") == sample][assay].tolist()\n",
    "                high_fraction = min(high_sample_data)\n",
    "                low_fraction = max(low_sample_data)\n",
    "                if high_fraction > low_fraction: \n",
    "                    correct_fractionation.append(assay)\n",
    "        if mean_median_individual == \"individual_median\":\n",
    "            high_fractions_values = []\n",
    "            for fraction in high_fractions:\n",
    "                if not high_fractions_df[assay].isna().all():\n",
    "                    high_fractions_values.append(high_fractions_df[high_fractions_df.index.get_level_values(\"Sample\").str.contains(fraction)][assay].median())\n",
    "            low_fractions_values = []\n",
    "            for fraction in low_fractions: \n",
    "                if not low_fractions_df[assay].isna().all():\n",
    "                    low_fractions_values.append(low_fractions_df[low_fractions_df.index.get_level_values(\"Sample\").str.contains(fraction)][assay].median())\n",
    "            if high_fractions_values:\n",
    "                high_fraction = min(high_fractions_values)\n",
    "            if low_fractions_values:\n",
    "                low_fraction = max(low_fractions_values)\n",
    "            if high_fraction > low_fraction: \n",
    "                correct_fractionation.append(assay)\n",
    "        if mean_median_individual == \"individual_mean\":\n",
    "            high_fractions_values = []\n",
    "            for fraction in high_fractions:\n",
    "                if not high_fractions_df[assay].isna().all():\n",
    "                    high_fractions_values.append(high_fractions_df[high_fractions_df.index.get_level_values(\"Sample\").str.contains(fraction)][assay].mean())\n",
    "            low_fractions_values = []\n",
    "            for fraction in low_fractions: \n",
    "                if not low_fractions_df[assay].isna().all():\n",
    "                    low_fractions_values.append(low_fractions_df[low_fractions_df.index.get_level_values(\"Sample\").str.contains(fraction)][assay].mean())\n",
    "            if high_fractions_values:\n",
    "                high_fraction = min(high_fractions_values)\n",
    "            if low_fractions_values:\n",
    "                low_fraction = max(low_fractions_values)\n",
    "            if high_fraction > low_fraction: \n",
    "                correct_fractionation.append(assay)\n",
    "    return correct_fractionation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_targets(correct_fractionation_uniprot_ids, cell_type_uniprot_ids, localization_uniprot_ids):\n",
    "    \"\"\"\n",
    "    Identifies targets that meet fractionation, cell-type specificity, and localization criteria.\n",
    "    Parameters: \n",
    "    ----------\n",
    "    'correct_fractionation_uniprot_ids': list\n",
    "        List of UniProt IDs that meet desired fractionation criteria. \n",
    "    'cell_type_uniprot_ids': list\n",
    "        List of UniProt IDs that meet desired cell-type specificity criteria.\n",
    "    'localization_uniprot_ids': list\n",
    "        List of UniProt IDs that meet desired localization criteria.\n",
    "    \"\"\"\n",
    "    return (set(correct_fractionation_uniprot_ids) & set(cell_type_uniprot_ids) & set(localization_uniprot_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_fractionation_pattern_cell_type_specific_targets(\n",
    "    assays_path, \n",
    "    uniprot_fasta_database, \n",
    "    region, \n",
    "    brain_rna_seq_path,\n",
    "    cell_type, \n",
    "    specificity_metric, \n",
    "    specificity_cutoff,\n",
    "    high_fractions,\n",
    "    low_fractions,\n",
    "    sample_health,\n",
    "    mean_median_individual,\n",
    "    raw_olink_data_file = 'none',\n",
    "    plate_layout_dataframe = 'none', \n",
    "    tidy_dataframe = 'none',\n",
    "    output_directory = 'olink_output',\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Identifies targets that meet specified fractionation, cell-type specificity, and localization criteria.\n",
    "    Parameters: \n",
    "    ----------\n",
    "    'assays_path': .xlsx file path\n",
    "        Path to a .xlsx file with a column containing the UniProt IDs of all the proteins in the Olink panel.\n",
    "    'uniprot_fasta_database': .gz file path\n",
    "        Path to a .gz file containing UniProt IDs and FASTA sequences.\n",
    "    'region': {'TMhelix', 'inside', 'outside', 'internal', 'external'}\n",
    "        Subcellular region requested. Options:\n",
    "          - 'TMhelix': transmembrane proteins\n",
    "          - 'inside': at least some of the protein is inside the cell/EV\n",
    "          - 'outside': at least some of the protein is outside the cell/EV\n",
    "          - 'internal': the protein is only found inside the cell, no transmembrane or outside domains\n",
    "          - 'external': the protein is only found outside the cell, no transmembrane or inside domains\n",
    "    'brain_rna_seq_path': csv file path\n",
    "        Path to the \"homo sapiens.csv\" file, downloaded from brainrnaseq.org.\n",
    "    'cell_type' : {'astrocyte', 'endothelial', 'microglia', 'oligodendrocyte', 'neuron'}\n",
    "        Cell type of interest requested. Options:\n",
    "         - 'astrocyte': mature astrocytes\n",
    "         - 'endothelial': endothelial cells\n",
    "         - 'microglia': microglia cells\n",
    "         - 'oligodendrocyte': oligodendrocytes\n",
    "         - 'neuron': neurons\n",
    "    'specificity_metric': {'tsi', 'zscore', 'spm', 'tau', 'gini', 'hg'}\n",
    "        Individualized metric of determining cell type specificity requested. Options:\n",
    "        - 'tsi': tissue specificity index\n",
    "        - 'zscore': z-score\n",
    "        - 'spm': specificity measure\n",
    "        - 'tau': tau index\n",
    "        - 'gini' : gini coefficient\n",
    "        - 'hg' : entropy of a gene's expression distribution\n",
    "    'specificity_cutoff' : numeric\n",
    "        Numeric value representing the minimum value of the second enrichment cutoff.\n",
    "    'high_fractions' : list of strings\n",
    "        Fractions that should be higher than the fractions in the list of low fractions.\n",
    "    'low_fractions' : list of strings\n",
    "        Fractions that should be lower than the fractions in the list of high fractions.\n",
    "    'sample_health' : {'all', 'ad', 'mci', 'mci_spectrum'}\n",
    "        Health of the sample requested. Options: \n",
    "            - 'healthy': only samples from healthy individuals\n",
    "            - 'all': all different health groups\n",
    "            - 'ad': samples from individuals diagnosed with Alzheimer's Disease (AD)\n",
    "            - 'mci': samples from individuals diagnosed with mild cognitive imapirment that has not yet progressed to AD\n",
    "            - 'mci_spectrum': samples from individuals diagnosed with mild cognitive impairment and samples from individuals that have been diagnosed with AD\n",
    "    'mean_median_individual' : {'mean', 'median', 'individual', 'individual_median', 'individual_mean'}\n",
    "        How the groups of samples should be analyzed. Options: \n",
    "            - 'mean': the means of each fraction should be compared against each other\n",
    "            - 'median': the medians of each fraction should be compared against each other\n",
    "            - 'individual': the fractions of each sample should be compared against each other with no aggregation/grouping \n",
    "            - 'individual_median': for each fraction, the median value of all samples will be compared\n",
    "            - 'individual_mean': for each fraction, the mean value of all samples will be compared\n",
    "        Default value: 'individual'\n",
    "    'raw_data_path': path to a .csv file, separated by semicolons\n",
    "        Path to the file containing the raw Olink data.\n",
    "    'plate_layout_dataframe': pandas.Dataframe\n",
    "        Dataframe containing information to map the SampleID of a sample to its description.\n",
    "    'tidy_dataframe' : pandas.DataFrame\n",
    "        DataFrame with one column for each assay, one row for each sample, linearized NPX as the vlaues, and the following indices:\n",
    "            - 'SampleID'\n",
    "            - 'Health'\n",
    "            - 'Sample'\n",
    "            - 'CSF_sample'\n",
    "    'output_directory': directory path\n",
    "        Path to a directory in which the localization data will be stored.\n",
    "    \"\"\"\n",
    "    if raw_olink_data_file != 'none' and plate_layout != 'none':\n",
    "            tidy_dataframe = clean_up_raw_olink_file(raw_olink_data_file, plate_layout_dataframe)\n",
    "\n",
    "    tidy_dataframe.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "    fasta_sequences = parse_gz_file(uniprot_fasta_database)\n",
    "    fasta_sequences.update({\"NTproBNP\": \"HPLGSPGSASDLETSGLQEQRNHLQGKLSELQVEQTSLEPLQESPRPTGVWKSREVATEGIRGHRKMVLYTLRAPR\",\n",
    "                            \"O43521-2\": \"MAKQPSDVSSECDREGRQLQPAERPPQLRPGAPTSLQTEPQDRSPAPMSCDKSTQTPSPPCQAFNHYLSAMASMRQAEPADMRPEIWIAQELRRIGDEFNAYYARRVFLNNYQAAEDHPRMVILRLLRYIVRLVWRMH\",\n",
    "                            \"Q13114-2\": \"MESSKKMDSPGALQTNPPLKLHTDRSAGTPVFVPEQGGYKEKFVKTVEDKYKCEKCHLVLCSPKQTECGHRFCESCMAALLSSSSPKCTACQESIVKDKVFKDNCCKREILALQIYCRNESRGCAEQLMLGHLLVHLKNDCHFEELPCVRPDCKEKVLRKDLRDHVEKACKYREATCSHCKSQVPMIALQVSLLQNESVEKNKSIQSLHNQICSFEIEIERQKEMLRNNESKILHLQRVIDSQAEKLKELDKEIRPFRQNWEEADSMKSSVESLQNRVTELESVDKSAGQVARNTGLLESQLSRHDQMLSVHDIRLADMDLRFQVLETASYNGVLIWKIRDYKRRKQEAVMGKTLSLYSQPFYTGYFGYKMCARVYLNGDGMGKGTHLSLFFVIMRGEYDALLPWPFKQKVTLMLMDQGSSRRHLGDAFKPDPNSSSFKKPTGEMNIASGCPVFVAQTVLENGTYIKDDTIFIKVIVDTSDLPDP\",\n",
    "                            \"O75882-2\": \"MVAAAAATEARLRRRTAATAALAGRSGGPHWDWDVTRAGRPGLGAGLRLPRLLSPPLRPRLLLLLLLLSPPLLLLLLPCEAEAAAAAAAVSGSAAAEAKECDRPCVNGGRCNPGTGQCVCPAGWVGEQCQHCGGRFRLTGSSGFVTDGPGNYKYKTKCTWLIEGQPNRIMRLRFNHFATECSWDHLYVYDGDSIYAPLVAAFSGLIVPERDGNETVPEVVATSGYALLHFFSDAAYNLTGFNITYSFDMCPNNCSGRGECKISNSSDTVECECSENWKGEACDIPHCTDNCGFPHRGICNSSDVRGCSCFSDWQGPGCSVPVPANQSFWTREEYSNLKLPRASHKAVVNGNIMWVVGGYMFNHSDYNMVLAYDLASREWLPLNRSVNNVVVRYGHSLALYKDKIYMYGGKIDSTGNVTNELRVFHIHNESWVLLTPKAKEQYAVVGHSAHIVTLKNGRVVMLVIFGHCPLYGYISNVQEYDLDKNTWSILHTQGALVQGGYGHSSVYDHRTRALYVHGGYKAFSANKYRLADDLYRYDVDTQMWTILKDSRFFRYLHTAVIVSGTMLVFGGNTHNDTSMSHGAKCFSSDFMAYDIACDRWSVLPRPDLHHDVNRFGHSAVLHNSTMYVFGGFNSLLLSDILVFTSEQCDAHRSEAACLAAGPGIRCVWNTGSSQCISWALATDEQEEKLKSECFSKRTLDHDRCDQHTDCYSCTANTNDCHWCNDHCVPRNHSCSEGQISIFRYENCPKDNPMYYCNKKTSCRSCALDQNCQWEPRNQECIALPENICGIGWHLVGNSCLKITTAKENYDNAKLFCRNHNALLASLTTQKKVEFVLKQLRIMQSSQSMSKLTLTPWVGLRKINVSYWCWEDMSPFTNSLLQWMPSEPSDAGFCGILSEPSTRGLKAATCINPLNGSVCERPANHSAKQCRTPCALRTACGDCTSGSSECMWCSNMKQCVDSNAYVASFPFGQCMEWYTMSTCPPENCSGYCTCSHCLEQPGCGWCTDPSNTGKGKCIEGSYKGPVKMPSQAPTGNFYPQPLLNSSMCLEDSRYNWSFIHCPACQCNGHSKCINQSICEKCENLTTGKHCETCISGFYGDPTNGGKCQPCKCNGHASLCNTNTGKCFCTTKGVKGDECQLCEVENRYQGNPLRGTCYYTLLIDYQFTFSLSQEDDRYYTAINFVATPDEQNRDLDMFINASKNFNLNITWAASFSAGTQAGEEMPVVSKTNIKEYKDSFSNEKFDFRNHPNITFFVYVSNFTWPIKIQVQTE\",\n",
    "                            \"Q8WXW3-4\": \"MSRKISKESKKVNISSSLESEDISLETTVPTDDISSSEEREGKVRITRQLIERKELLHNIQLLKIELSQKTMMIDNLKVDYLTKIEELEEKLNDALHQKQLLTLRLDNQLAFQQKDASKYQELMKQEMETILLRQKQLEETNLQLREKAGDVRRNLRDFELTEEQYIKLKAFPEDQLSIPEYVSVRFYELVNPLRKEICELQVKKNILAEELSTNKNQLKQLTEELAAMKQILVKMHSKHSENSLLLTKTEPKHVTENQKSKTLNVPKEHEDNIFTPKPTLFTKKEAPEWSKKQKMKT\",\n",
    "                            })\n",
    "    assays = pd.read_excel(assays_path)\n",
    "    assays[\"Sequence\"] = assays[\"UniProt ID\"].map(lambda x: fasta_sequences.get(x, \"N/A\"))\n",
    "    localization_uniprot_ids = identify_localization(assays, region, output_directory)\n",
    "\n",
    "    brain_rna_seq = map_hgnc_ids(brain_rna_seq_path)\n",
    "    cell_type_uniprot_ids = cell_type_enrichment(brain_rna_seq, cell_type, specificity_metric, specificity_cutoff)\n",
    "\n",
    "    correct_fractionation_uniprot_ids = analyze_fractionation(tidy_dataframe, high_fractions, low_fractions, sample_health, mean_median_individual)\n",
    "\n",
    "    return identify_targets(\n",
    "        correct_fractionation_uniprot_ids, \n",
    "        cell_type_uniprot_ids, \n",
    "        localization_uniprot_ids\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSF_SAMPLES = [\n",
    "    \"SEC Fract 6 \",\n",
    "    \"SEC Fract 7\",\n",
    "    \"SEC Fract 8\",\n",
    "    \"SEC Fract 9\",\n",
    "    \"SEC Fract 10\",\n",
    "    \"SEC Fract 11\",\n",
    "    \"SEC Fract 12\",\n",
    "    \"SEC Fract 13\",\n",
    "    \"SEC Fract 14\",\n",
    "    \"SEC Fract 15\",\n",
    "    # \"CSF A Internal EV\",\n",
    "    # \"CSF B Internal EV\",\n",
    "    # \"CSF C Internal EV\",\n",
    "    # \"CSF D Internal EV\",\n",
    "]\n",
    "\n",
    "\n",
    "def graph_ht_medians(uniprot_id):\n",
    "    df = tidy_ht_data[uniprot_id]\n",
    "    df = df[df.index.get_level_values(\"Health\") == \"Healthy\"]\n",
    "    df = df.reset_index(level=[\"SampleID\", \"Health\", \"Sample\"])\n",
    "    df[\"Sample\"] = pd.Categorical(df[\"Sample\"], categories=CSF_SAMPLES, ordered=True)\n",
    "    df_sorted = df.sort_values(\"Sample\")\n",
    "    grouped_data = [\n",
    "        group[uniprot_id].values for name, group in df_sorted.groupby(\"Sample\")\n",
    "    ]\n",
    "    plt.boxplot(grouped_data, notch=None, vert=None, patch_artist=None, widths=None)\n",
    "    plt.xlabel(\"Sample Description\")\n",
    "    plt.ylabel(\"Delta\")\n",
    "    plt.title(f\"Healthy {uniprot_id} Fractionation Pattern, HT Panel\")\n",
    "    plt.xticks(range(1, len(CSF_SAMPLES) + 1), CSF_SAMPLES)\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.show()\n",
    "\n",
    "def graph_explore_medians(uniprot_id):\n",
    "    df = tidy_explore_data[uniprot_id]\n",
    "    df = df[df.index.get_level_values(\"Health\") == \"Healthy\"]\n",
    "    df = df.reset_index(level=[\"SampleID\", \"Health\", \"Sample\"])\n",
    "    df[\"Sample\"] = pd.Categorical(df[\"Sample\"], categories=CSF_SAMPLES, ordered=True)\n",
    "    df_sorted = df.sort_values(\"Sample\")\n",
    "    grouped_data = [\n",
    "        group[uniprot_id].values for name, group in df_sorted.groupby(\"Sample\")\n",
    "    ]\n",
    "    plt.boxplot(grouped_data, notch=None, vert=None, patch_artist=None, widths=None)\n",
    "    plt.xlabel(\"Sample Description\")\n",
    "    plt.ylabel(\"Delta\")\n",
    "    plt.title(f\"Healthy {uniprot_id} Fractionation Pattern, Explore Panel\")\n",
    "    plt.xticks(range(1, len(CSF_SAMPLES) + 1), CSF_SAMPLES)\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
