{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\n",
    "    \"C:\\\\Users\\\\Wyss User\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python311\\\\site-packages\"\n",
    ")\n",
    "\n",
    "import biolib\n",
    "import gzip\n",
    "import os\n",
    "import requests\n",
    "import pathlib\n",
    "import scipy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_rna_seq_path = (\n",
    "    \"C:\\\\Users\\\\Wyss User\\\\Documents\\\\EVs\\\\OLINK\\\\supplemental_files\\\\fe-wp-dataset-124.csv\"\n",
    ")\n",
    "raw_data = \"C:\\\\Users\\\\Wyss User\\\\Documents\\\\EVs\\\\OLINK\\\\supplemental_files\\\\LCSET-29370_AShah_MNorman_Extended_NPX_2024-02-14.parquet\"\n",
    "uniprot_fasta_database = (\n",
    "    \"C:\\\\Users\\\\Wyss User\\\\Documents\\\\EVs\\\\OLINK\\\\uniprot_fasta_database.gz\"\n",
    ")\n",
    "plate_layout_path = \"C:\\\\Users\\\\Wyss User\\\\Documents\\\\EVs\\\\OLINK\\\\supplemental_files\\\\Plate Layout.xlsx\"\n",
    "assay_list_path = (\n",
    "    \"C:\\\\Users\\\\Wyss User\\\\Documents\\\\EVs\\\\OLINK\\\\supplemental_files\\\\ht_panel_assay_list.xlsx\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_gz_file(file_path):\n",
    "    \"\"\"\n",
    "    Creates a dictionary of UniProt IDs and their corresponding FASTA sequences using a .gz file.\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path: path to a .gz file containing UniProt IDs and FASTA sequences.\n",
    "    \"\"\"\n",
    "    protein_dict = {}\n",
    "    current_uniprot_id = None\n",
    "    current_sequence = \"\"\n",
    "    with gzip.open(file_path, \"rt\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\">\"):\n",
    "                if current_uniprot_id is not None:\n",
    "                    protein_dict[current_uniprot_id] = current_sequence\n",
    "                    current_sequence = \"\"\n",
    "                if \"|\" in line:\n",
    "                    current_uniprot_id = line.split(\"|\")[1].strip()\n",
    "                else:\n",
    "                    print(f\"Skipping line without expected format: {line}\")\n",
    "                    current_uniprot_id = None\n",
    "            else:\n",
    "                current_sequence += line\n",
    "        if current_uniprot_id is not None:\n",
    "            protein_dict[current_uniprot_id] = current_sequence\n",
    "    return protein_dict\n",
    "\n",
    "\n",
    "def tmhmm_localization(assays, output_directory):\n",
    "    \"\"\"\n",
    "    Uses DeepTMHMM to characterize the localization of each amino acid in a protein.\n",
    "    Parameters\n",
    "    ----------\n",
    "    assays : pandas.DataFrame\n",
    "        DataFrame with columns called 'UniProt ID' and 'Sequence'\n",
    "    \"\"\"\n",
    "    deeptmhmm = biolib.load(\"DTU/DeepTMHMM\")\n",
    "    assay_list = []\n",
    "    with open(\"query.fasta\", \"w\") as fasta_file:\n",
    "        for _, row in assays.iterrows():\n",
    "            fasta_line = f\">{row['UniProt ID']}\\n{row['Sequence']}\\n\"\n",
    "            fasta_file.write(fasta_line)\n",
    "            assay_list.append(fasta_line)\n",
    "    deeptmhmm_job = deeptmhmm.cli(args=\"--fasta query.fasta\", machine=\"local\")\n",
    "    deeptmhmm_job.save_files(output_directory)\n",
    "\n",
    "\n",
    "def identify_localization(assays, region, output_directory=\"ht_output\"):\n",
    "    \"\"\"\n",
    "    Identifies the localization of proteins using the output of DeepTMHMM.\n",
    "    Parameters\n",
    "    ----------\n",
    "    assays : pandas.DataFrame\n",
    "        DataFrame with columns called 'UniProt ID' and 'Sequence'\n",
    "    region : {'TMhelix', 'inside', 'outside', 'internal', 'external'}\n",
    "        Subcellular region requested. Options:\n",
    "          - 'TMhelix': transmembrane proteins\n",
    "          - 'inside': at least some of the protein is inside the cell/EV\n",
    "          - 'outside': at least some of the protein is outside the cell/EV\n",
    "          - 'internal': the protein is only found inside the cell, no transmembrane or outside domains\n",
    "          - 'external': the protein is only found outside the cell, no transmembrane or inside domains\n",
    "    output_directory: directory path\n",
    "        Path to a directory in which the localization data will be stored.\n",
    "    \"\"\"\n",
    "    output_directory_path = pathlib.Path(output_directory)\n",
    "    if not os.path.exists(output_directory_path):\n",
    "        os.makedirs(output_directory_path)\n",
    "    if not os.path.exists(output_directory_path / \"TMRs.gff3\"):\n",
    "        tmhmm_localization(assays, output_directory_path)\n",
    "    localization_df = pd.read_csv(\n",
    "        output_directory_path / \"TMRs.gff3\",\n",
    "        sep=\"\\t\",\n",
    "        comment=\"#\",\n",
    "        names=[\n",
    "            \"uniprot_id\",\n",
    "            \"region_location\",\n",
    "            \"region_start\",\n",
    "            \"region_end\",\n",
    "            0,\n",
    "            1,\n",
    "            2,\n",
    "            3,\n",
    "        ],\n",
    "    )\n",
    "    localization_df = localization_df[localization_df[\"uniprot_id\"] != \"//\"].dropna(\n",
    "        axis=1\n",
    "    )\n",
    "    get_regional_uniprots = lambda region: set(\n",
    "        localization_df[localization_df[\"region_location\"] == region][\"uniprot_id\"]\n",
    "    )\n",
    "    if region == \"internal\":\n",
    "        tm_uniprots = get_regional_uniprots(\"TMhelix\")\n",
    "        outside_uniprots = get_regional_uniprots(\"outside\")\n",
    "        inside_uniprots = get_regional_uniprots(\"inside\")\n",
    "        return inside_uniprots - tm_uniprots - outside_uniprots\n",
    "    if region == \"external\":\n",
    "        tm_uniprots = get_regional_uniprots(\"TMhelix\")\n",
    "        outside_uniprots = get_regional_uniprots(\"outside\")\n",
    "        inside_uniprots = get_regional_uniprots(\"inside\")\n",
    "        return outside_uniprots - inside_uniprots - tm_uniprots\n",
    "    else:\n",
    "        return get_regional_uniprots(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_strings(strings):\n",
    "    \"\"\"\n",
    "    Gets rid of possible sources of error among strings in a list.\n",
    "    Parameters\n",
    "    ----------\n",
    "    strings : a list of strings.\n",
    "    \"\"\"\n",
    "    cleaned_strings = []\n",
    "    for string in strings:\n",
    "        cleaned_string = (\n",
    "            str(string)\n",
    "            .replace(\"(\", \"\")\n",
    "            .replace(\")\", \"\")\n",
    "            .replace(\"'\", \"\")\n",
    "            .replace(\",\", \"\")\n",
    "        )\n",
    "        cleaned_strings.append(cleaned_string)\n",
    "    return cleaned_strings\n",
    "\n",
    "\n",
    "def clean_up_raw_data(raw_data, plate_layout_path):\n",
    "    \"\"\"\n",
    "    Normalizes all data points and converts to a tidy dataframe.\n",
    "    Parameters\n",
    "    ----------\n",
    "    raw_data: .parquet file path\n",
    "        Path to the raw parquet file provided by Olink containing sample data.\n",
    "    plate_layout_path: .xlsx file path\n",
    "        Path to an excel file used to map the SampleIDs to any information.\n",
    "    \"\"\"\n",
    "    ht_data = pd.read_parquet(raw_data)\n",
    "    plate_layout = pd.read_excel(plate_layout_path)\n",
    "    data = pd.merge(ht_data, plate_layout, how=\"left\", on=\"SampleID\")\n",
    "    # repeat assays: P32455, Q02750\n",
    "    replicate_assays = data[[\"UniProt\"]].value_counts()\n",
    "    replicate_assays = replicate_assays[replicate_assays > 94]\n",
    "    replicate_assay_list = clean_strings(replicate_assays.index.tolist())\n",
    "    unique_data = data[~data[\"UniProt\"].isin(replicate_assay_list)]\n",
    "    ctrl_dict = {}\n",
    "    for assay in list(unique_data[\"Assay\"].unique()):\n",
    "        df = unique_data[unique_data[\"Assay\"] == assay]\n",
    "        neg_ctrl = df[df[\"SampleType\"] == \"NEGATIVE_CONTROL\"][\n",
    "            \"PCNormalizedNPX\"\n",
    "        ].median()\n",
    "        ctrl_dict[assay] = neg_ctrl\n",
    "    unique_data[\"Delta\"] = unique_data.apply(\n",
    "        lambda row: (\n",
    "            row[\"PCNormalizedNPX\"] - ctrl_dict[row[\"Assay\"]]\n",
    "            if row[\"PCNormalizedNPX\"] >= ctrl_dict[row[\"Assay\"]]\n",
    "            else ctrl_dict[row[\"Assay\"]]\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "    unique_data.loc[:, \"Linear NPX\"] = unique_data[\"PCNormalizedNPX\"].map(lambda x: 2**x)\n",
    "    tidy_data = unique_data[unique_data[\"SampleType\"] == \"SAMPLE\"].pivot(\n",
    "        columns=\"UniProt\",\n",
    "        index=[\"SampleID\", \"Health\", \"Sample\", \"CSF_sample\"],\n",
    "        values=\"Linear NPX\",\n",
    "    )\n",
    "    return tidy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_type_dict = {\n",
    "    \"microglia\" : \"microglla\",\n",
    "    \"astrocyte\" : \"mature\",\n",
    "    \"oligodendrocyte\" : \"oligodendrocyte\",\n",
    "    \"neuron\" : \"neuron\",\n",
    "    \"endothelial\" : \"endothelial\"\n",
    "}\n",
    "\n",
    "def calculate_mean(df):\n",
    "    \"\"\"\n",
    "    Calculates the mean of all numeric values in a row of a dataframe, and assigns to a new column called \"Mean\".\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pandas.DataFrame\n",
    "        Dataframe with columns containing numeric values.\n",
    "    \"\"\"\n",
    "    return df.assign(Mean=df.mean(axis=1, numeric_only=True))\n",
    "\n",
    "\n",
    "def map_hgnc_ids(brain_rna_seq_path):\n",
    "    \"\"\"\n",
    "    Maps the HGNC IDs in the Brain RNA-Seq file to UniProt IDs.\n",
    "    Parameters\n",
    "    ----------\n",
    "    brain_rna_seq_path: csv file path\n",
    "        Path to the \"homo sapiens.csv\" file, downloaded from brainrnaseq.org.\n",
    "    \"\"\"\n",
    "    hgnc_ids = (\n",
    "        \"https://ftp.ebi.ac.uk/pub/databases/genenames/hgnc/tsv/hgnc_complete_set.txt\"\n",
    "    )\n",
    "    brain_rna_seq = pd.read_csv(brain_rna_seq_path)\n",
    "\n",
    "    hgnc_uniprot_mapping_data = pd.read_csv(\n",
    "        (StringIO(requests.get(hgnc_ids).text)),\n",
    "        sep=\"\\t\",\n",
    "        usecols=[\"hgnc_id\", \"uniprot_ids\"],\n",
    "    )\n",
    "\n",
    "    hgnc_uniprot_mapping_data[\"uniprot_ids\"] = hgnc_uniprot_mapping_data[\n",
    "        \"uniprot_ids\"\n",
    "    ].str.split(\"|\")\n",
    "    hgnc_uniprot_mapping_data = hgnc_uniprot_mapping_data.explode(\"uniprot_ids\")\n",
    "    hgnc_uniprot_mapping_data = hgnc_uniprot_mapping_data.reset_index(drop=True)\n",
    "\n",
    "    brain_rna_seq = pd.merge(\n",
    "        brain_rna_seq,\n",
    "        hgnc_uniprot_mapping_data,\n",
    "        left_on=\"id\",\n",
    "        right_on=\"hgnc_id\",\n",
    "        how=\"inner\",\n",
    "    )\n",
    "    brain_rna_seq.dropna(subset=[\"uniprot_ids\"], inplace=True)\n",
    "    brain_rna_seq.drop_duplicates(subset=[\"uniprot_ids\"], inplace=True)\n",
    "    brain_rna_seq.set_index(\"uniprot_ids\", inplace = True)\n",
    "\n",
    "    return brain_rna_seq\n",
    "\n",
    "\n",
    "def mean_cell_type(brain_rna_seq_data, cell_type):\n",
    "    \"\"\"\n",
    "    Returns only the mean of the data for the specified cell type, as well as the UniProt ID information in an additional column\n",
    "    Parameters\n",
    "    ----------\n",
    "    brain_rna_seq_data : pandas.DataFrame\n",
    "        Dataframe with a column called \"uniprot_ids\" (contains UniProt ID), and other columns containing cell-type specific Brain RNA Seq data\n",
    "    cell_type : {'astrocyte', 'endothelial', 'microglia', 'oligodendrocyte', 'neuron'}\n",
    "        Cell type of interest requested. Options:\n",
    "         - 'astrocyte': mature astrocytes\n",
    "         - 'endothelial': endothelial cells\n",
    "         - 'microglia': microglia cells\n",
    "         - 'oligodendrocyte': oligodendrocytes\n",
    "         - 'neuron': neurons\n",
    "    \"\"\"\n",
    "    \n",
    "    key = cell_type_dict[str(cell_type)]\n",
    "    cell_type_df = brain_rna_seq_data.filter(like=str(key), axis = 1)\n",
    "    means_df = calculate_mean(cell_type_df)\n",
    "    return means_df.rename(\n",
    "        columns={\"uniprot_ids\": \"uniprot_ids\", \"Mean\": key}\n",
    "    )\n",
    "\n",
    "\n",
    "def calculate_enrichment(row, specificity_metric):\n",
    "    \"\"\"\n",
    "    Uses the numeric values in a row of a dataframe (with the row being expression data for a specific gene of interest) to determine a gene's specificity Returns a numpy array with an index of indentifier for the gene and values of specificity scores.\n",
    "    Parameters\n",
    "    ----------\n",
    "    'row' : pandas.DataFrame\n",
    "        Row of a DataFrame containing expression data for a gene of interest with one column for each cell type/tissue being analyzed. Index should be identifier for each gene.\n",
    "    'specificity_metric' : {'tau', 'tsi', 'gini', 'hg', 'spm', 'zscore'}\n",
    "        Method to determine specificity requested. Options:\n",
    "            - tau: Tau specificity score\n",
    "            - tsi: Tissue Specificity Index\n",
    "            - gini: Gini coefficient\n",
    "            - hg: Entropy of a gene's expression distribution\n",
    "            - spm: Specificity Metric\n",
    "            - zscore: Z-score\n",
    "    References\n",
    "    ----------\n",
    "    Kryuchkova-Mostacci N, Robinson-Rechavi M. A benchmark of gene expression tissue-specificity metrics. Brief Bioinform. 2017 Mar 1;18(2):205-214. doi: 10.1093/bib/bbw008. PMID: 26891983; PMCID: PMC5444245.\n",
    "    Schug J, Schuller WP, Kappen C, Salbaum JM, Bucan M, Stoeckert CJ Jr. Promoter features related to tissue specificity as measured by Shannon entropy. Genome Biol. 2005;6(4):R33. doi: 10.1186/gb-2005-6-4-r33. Epub 2005 Mar 29. PMID: 15833120; PMCID: PMC1088961.\n",
    "    Wright Muelas, M., Mughal, F., O’Hagan, S. et al. The role and robustness of the Gini coefficient as an unbiased tool for the selection of Gini genes for normalising expression profiling data. Sci Rep 9, 17960 (2019). https://doi.org/10.1038/s41598-019-54288-7.\n",
    "    \"\"\"\n",
    "    row_array = np.array(row)\n",
    "    if specificity_metric == \"tau\":\n",
    "        row_x = row_array / max(row_array)\n",
    "        return np.sum(1 - row_x) / ((len(row_x)) - 1)\n",
    "    if specificity_metric == \"tsi\":\n",
    "        return max(row_array) / sum(row_array)\n",
    "    if specificity_metric == \"gini\":\n",
    "        sorted_types = np.sort(row_array)\n",
    "        cumulative_fraction_types = np.cumsum(sorted_types) / np.sum(sorted_types)\n",
    "        cumulative_fraction_total = np.linspace(0, 1, len(sorted_types))\n",
    "        area_under_line_of_perfect_equality = scipy.integrate.simps(\n",
    "            cumulative_fraction_total, cumulative_fraction_total\n",
    "        )\n",
    "        area_under_lorenz_curve = scipy.integrate.simps(\n",
    "            cumulative_fraction_types, cumulative_fraction_total\n",
    "        )\n",
    "        return area_under_line_of_perfect_equality / (\n",
    "            area_under_line_of_perfect_equality + area_under_lorenz_curve\n",
    "        )\n",
    "    if specificity_metric == \"hg\":\n",
    "        row_sum = np.sum(row_array)\n",
    "        p_sub_i = row_array / row_sum\n",
    "        return -1 * (sum(p_sub_i * np.log2(p_sub_i)))\n",
    "    if specificity_metric == \"spm\":\n",
    "        squared_array = row_array**2\n",
    "        sum_squared_array = np.sum(squared_array)\n",
    "        spm_score = squared_array / sum_squared_array\n",
    "        return pd.Series(spm_score, index=row.index)\n",
    "    if specificity_metric == \"zscore\":\n",
    "        mean_array = np.mean(row_array)\n",
    "        std_array = np.std(row_array)\n",
    "        zscore_values = (row_array - mean_array) / std_array\n",
    "        return pd.Series(zscore_values, index=row.index)\n",
    "\n",
    "\n",
    "def cell_type_enrichment(\n",
    "    brain_rna_seq_data,\n",
    "    cell_type,\n",
    "    specificity_metric,\n",
    "    specificity_cutoff,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns a list of UniProt IDs corresponding to targets that meet specified criteria to determine cell-type specificity.\n",
    "    Parameters\n",
    "    ----------\n",
    "    'brain_rna_seq_data' : pandas.DataFrame\n",
    "        Dataframe with a column called \"uniprot_ids\" (contains UniProt ID), and other columns containing cell-type specific Brain RNA Seq data for the cell types listed under cell_type\n",
    "    'cell_type' : {'astrocyte', 'endothelial', 'microglia', 'oligodendrocyte', 'neuron'}\n",
    "        Cell type of interest requested. Options:\n",
    "         - 'astrocyte': mature astrocytes\n",
    "         - 'endothelial': endothelial cells\n",
    "         - 'microglia': microglia cells\n",
    "         - 'oligodendrocyte': oligodendrocytes\n",
    "         - 'neuron': neurons\n",
    "    'specificity_metric': {'tsi', 'zscore', 'spm', 'tau', 'gini', 'hg'}\n",
    "        Individualized metric of determining cell type specificity requested. Options:\n",
    "        - 'tsi': tissue specificity index\n",
    "        - 'zscore': z-score\n",
    "        - 'spm': specificity measure\n",
    "        - 'tau': tau index\n",
    "        - 'gini' : gini coefficient\n",
    "        - 'hg' : entropy of a gene's expression distribution\n",
    "    'specificity_cutoff' : numeric\n",
    "        Numeric value representing the minimum value of the second enrichment cutoff.\n",
    "    References\n",
    "    ----------\n",
    "    Kryuchkova-Mostacci N, Robinson-Rechavi M. A benchmark of gene expression tissue-specificity metrics. Brief Bioinform. 2017 Mar 1;18(2):205-214. doi: 10.1093/bib/bbw008. PMID: 26891983; PMCID: PMC5444245.\n",
    "    Schug J, Schuller WP, Kappen C, Salbaum JM, Bucan M, Stoeckert CJ Jr. Promoter features related to tissue specificity as measured by Shannon entropy. Genome Biol. 2005;6(4):R33. doi: 10.1186/gb-2005-6-4-r33. Epub 2005 Mar 29. PMID: 15833120; PMCID: PMC1088961.\n",
    "    Wright Muelas, M., Mughal, F., O’Hagan, S. et al. The role and robustness of the Gini coefficient as an unbiased tool for the selection of Gini genes for normalising expression profiling data. Sci Rep 9, 17960 (2019). https://doi.org/10.1038/s41598-019-54288-7.\n",
    "    \"\"\"\n",
    "\n",
    "    astrocytes = mean_cell_type(brain_rna_seq_data, \"astrocyte\")\n",
    "    endothelial = mean_cell_type(brain_rna_seq_data, \"endothelial\")\n",
    "    microglia = mean_cell_type(brain_rna_seq_data, \"microglia\")\n",
    "    oligodendrocytes = mean_cell_type(brain_rna_seq_data, \"oligodendrocyte\")\n",
    "    neurons = mean_cell_type(brain_rna_seq_data, \"neuron\")\n",
    "\n",
    "    all_cell_types = pd.merge(\n",
    "        pd.merge(\n",
    "            pd.merge(\n",
    "                pd.merge(astrocytes, endothelial, left_index=True, right_index = True),\n",
    "                microglia,\n",
    "                left_index=True, right_index = True,\n",
    "            ),\n",
    "            oligodendrocytes,\n",
    "            left_index=True, right_index = True,\n",
    "        ),\n",
    "        neurons,\n",
    "        left_index=True, right_index = True,\n",
    "    )\n",
    "    all_cell_types = all_cell_types[[\"mature\", \"microglla\", \"endothelial\", \"oligodendrocyte\", \"neuron\"]]\n",
    "    cell_type_dict_inverted = {v: k for k, v in cell_type_dict.items()}\n",
    "    all_cell_types = all_cell_types.rename(columns = cell_type_dict_inverted)\n",
    "\n",
    "    cell_type_uniprot_ids = []\n",
    "\n",
    "    if specificity_metric == \"enrichment\":\n",
    "        other_cell_types = all_cell_types.drop(cell_type, axis=1)\n",
    "        cell_type_targets = all_cell_types[[cell_type]]\n",
    "        cell_type_targets[\"comparison\"] = other_cell_types.apply(\n",
    "            lambda row: row.max(), axis=1\n",
    "        )\n",
    "        if cell_type != \"all\":\n",
    "            for index, row in cell_type_targets.iterrows():\n",
    "                cell_type_uniprot_ids.append(\n",
    "                    row[\n",
    "                        (row[cell_type]) > (row[\"comparison\"] * specificity_cutoff)\n",
    "                    ].index\n",
    "                )\n",
    "        if cell_type == \"all\":\n",
    "            for index, row in cell_type_targets.iterrows():\n",
    "                cell_type_uniprot_ids.append(\n",
    "                    row[\n",
    "                        (row[cell_type]) < (row[\"comparison\"] * specificity_cutoff)\n",
    "                    ].index\n",
    "                )\n",
    "    else:\n",
    "        enrichment_values = all_cell_types.apply(\n",
    "            lambda row: calculate_enrichment(row, specificity_metric), axis=1\n",
    "        )\n",
    "        if cell_type != \"all\":\n",
    "            if specificity_metric == \"zscore\" or specificity_metric == \"spm\":\n",
    "                cell_type_uniprot_ids = enrichment_values[\n",
    "                    (enrichment_values[cell_type]) > (specificity_cutoff)\n",
    "                ].index.tolist()\n",
    "            if (\n",
    "                specificity_metric == \"tau\"\n",
    "                or specificity_metric == \"gini\"\n",
    "                or specificity_metric == \"hg\"\n",
    "                or specificity_metric == \"tsi\"\n",
    "            ):\n",
    "                cell_type_uniprots = enrichment_values[\n",
    "                    enrichment_values > specificity_cutoff\n",
    "                ].index.tolist()\n",
    "                cell_type_df = all_cell_types.loc[cell_type_uniprots]\n",
    "                for index, row in cell_type_df.iterrows():\n",
    "                    max_column = row.idxmax()\n",
    "                    if max_column == cell_type:\n",
    "                        cell_type_uniprot_ids.append(index)\n",
    "\n",
    "        if cell_type == \"all\":\n",
    "            if specificity_metric == \"tau\" or \"gini\" or \"hg\" or \"tsi\":\n",
    "                df = enrichment_values[\n",
    "                    enrichment_values < specificity_cutoff\n",
    "                ].index.tolist()\n",
    "            else:\n",
    "                for index, row in enrichment_values.iterrows():\n",
    "                    cell_type_uniprot_ids = enrichment_values[\n",
    "                        (enrichment_values[cell_type]) > (specificity_cutoff)\n",
    "                    ].index.tolist()\n",
    "\n",
    "    return cell_type_uniprot_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_fractionation(\n",
    "    tidy_dataframe,\n",
    "    high_fractions,\n",
    "    low_fractions,\n",
    "    sample_health=\"all\",\n",
    "    mean_median_individual=\"individual\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    'tidy_dataframe' : pandas.DataFrame\n",
    "        DataFrame with one column for each assay, one row for each sample, linearized NPX as the vlaues, and the following indices:\n",
    "            - 'SampleID'\n",
    "            - 'Health'\n",
    "            - 'Sample'\n",
    "            - 'CSF_sample'\n",
    "    'high_fractions' : list of strings\n",
    "        Fractions that should be higher than the fractions in the list of low fractions.\n",
    "    'low_fractions' : list of strings\n",
    "        Fractions that should be lower than the fractions in the list of high fractions.\n",
    "    'sample_health' : {'all', 'ad', 'mci', 'mci_spectrum'}\n",
    "        Health of the sample requested. Options:\n",
    "            - 'healthy': only samples from healthy individuals\n",
    "            - 'all': all different health groups\n",
    "            - 'ad': samples from individuals diagnosed with Alzheimer's Disease (AD)\n",
    "            - 'mci': samples from individuals diagnosed with mild cognitive imapirment that has not yet progressed to AD\n",
    "            - 'mci_spectrum': samples from individuals diagnosed with mild cognitive impairment and samples from individuals that have been diagnosed with AD\n",
    "    'mean_median_individual' : {'mean', 'median', 'individual', 'individual_median', 'individual_mean'}\n",
    "        How the groups of samples should be analyzed. Options:\n",
    "            - 'mean': the means of each fraction should be compared against each other\n",
    "            - 'median': the medians of each fraction should be compared against each other\n",
    "            - 'individual': the fractions of each sample should be compared against each other with no aggregation/grouping\n",
    "            - 'individual_median': for each fraction, the median value of all samples will be compared\n",
    "            - 'individual_mean': for each fraction, the mean value of all samples will be compared\n",
    "        Default value: 'individual'\n",
    "    \"\"\"\n",
    "\n",
    "    non_ppa_data = tidy_dataframe[\n",
    "        tidy_dataframe.index.get_level_values(\"Sample\").str.contains(\"SEC\")\n",
    "    ]\n",
    "    if sample_health == \"healthy\":\n",
    "        requested_health_data = non_ppa_data[\n",
    "            non_ppa_data.index.get_level_values(\"Health\").str.contains(\"Healthy\")\n",
    "        ]\n",
    "    if sample_health == \"all\":\n",
    "        requested_health_data = non_ppa_data\n",
    "    if sample_health == \"ad\":\n",
    "        requested_health_data = non_ppa_data[\n",
    "            non_ppa_data.index.get_level_values(\"Health\").str.contains(\"AD\")\n",
    "        ]\n",
    "    if sample_health == \"mci\":\n",
    "        requested_health_data = non_ppa_data[\n",
    "            non_ppa_data.index.get_level_values(\"Health\").str.contains(\"MCI\")\n",
    "        ]\n",
    "    if sample_health == \"mci_spectrum\":\n",
    "        requested_health_data = non_ppa_data[\n",
    "            (non_ppa_data.index.get_level_values(\"Health\").str.contains(\"AD\"))\n",
    "            | (non_ppa_data.index.get_level_values(\"Health\").str.contains(\"MCI\"))\n",
    "        ]\n",
    "\n",
    "    high_fractions_dataframes = {}\n",
    "    for fraction in high_fractions:\n",
    "        high_fractions_dataframes[fraction] = requested_health_data[\n",
    "            requested_health_data.index.get_level_values(\"Sample\").str.contains(\n",
    "                fraction\n",
    "            )\n",
    "        ]\n",
    "    high_fractions_df = pd.concat(high_fractions_dataframes.values(), axis=0)\n",
    "    low_fractions_dataframes = {}\n",
    "    for fraction in low_fractions:\n",
    "        low_fractions_dataframes[fraction] = requested_health_data[\n",
    "            requested_health_data.index.get_level_values(\"Sample\").str.contains(\n",
    "                fraction\n",
    "            )\n",
    "        ]\n",
    "    low_fractions_df = pd.concat(low_fractions_dataframes.values(), axis=0)\n",
    "\n",
    "    correct_fractionation = []\n",
    "\n",
    "    for assay in list(non_ppa_data.columns):\n",
    "        if mean_median_individual == \"median\":\n",
    "            if not high_fractions_df[assay].isna().all():\n",
    "                high_fractions = high_fractions_df[assay].median()\n",
    "\n",
    "            if not low_fractions_df[assay].isna().all():\n",
    "                low_fractions = low_fractions_df[assay].median()\n",
    "            if high_fractions > low_fractions:\n",
    "                correct_fractionation.append(assay)\n",
    "        if mean_median_individual == \"mean\":\n",
    "            if not high_fractions_df[assay].isna().all():\n",
    "                high_fractions = high_fractions_df[assay].mean()\n",
    "            if not low_fractions_df[assay].isna().all():\n",
    "                low_fractions = low_fractions_df[assay].mean()\n",
    "            if high_fractions > low_fractions:\n",
    "                correct_fractionation.append(assay)\n",
    "        if mean_median_individual == \"individual\":\n",
    "            for sample in list(\n",
    "                requested_health_data.index.get_level_values(\"CSF_sample\").unique()\n",
    "            ):\n",
    "                high_sample_data = high_fractions_df[\n",
    "                    high_fractions_df.index.get_level_values(\"CSF_sample\") == sample\n",
    "                ][assay].tolist()\n",
    "                low_sample_data = low_fractions_df[\n",
    "                    low_fractions_df.index.get_level_values(\"CSF_sample\") == sample\n",
    "                ][assay].tolist()\n",
    "                high_fraction = min(high_sample_data)\n",
    "                low_fraction = max(low_sample_data)\n",
    "                if high_fraction > low_fraction:\n",
    "                    correct_fractionation.append(assay)\n",
    "        if mean_median_individual == \"individual_median\":\n",
    "            high_fractions_values = []\n",
    "            for fraction in high_fractions:\n",
    "                if not high_fractions_df[assay].isna().all():\n",
    "                    high_fractions_values.append(\n",
    "                        high_fractions_df[\n",
    "                            high_fractions_df.index.get_level_values(\n",
    "                                \"Sample\"\n",
    "                            ).str.contains(fraction)\n",
    "                        ][assay].median()\n",
    "                    )\n",
    "            low_fractions_values = []\n",
    "            for fraction in low_fractions:\n",
    "                if not low_fractions_df[assay].isna().all():\n",
    "                    low_fractions_values.append(\n",
    "                        low_fractions_df[\n",
    "                            low_fractions_df.index.get_level_values(\n",
    "                                \"Sample\"\n",
    "                            ).str.contains(fraction)\n",
    "                        ][assay].median()\n",
    "                    )\n",
    "            if high_fractions_values:\n",
    "                high_fraction = min(high_fractions_values)\n",
    "            if low_fractions_values:\n",
    "                low_fraction = max(low_fractions_values)\n",
    "            if high_fraction > low_fraction:\n",
    "                correct_fractionation.append(assay)\n",
    "        if mean_median_individual == \"individual_mean\":\n",
    "            high_fractions_values = []\n",
    "            for fraction in high_fractions:\n",
    "                if not high_fractions_df[assay].isna().all():\n",
    "                    high_fractions_values.append(\n",
    "                        high_fractions_df[\n",
    "                            high_fractions_df.index.get_level_values(\n",
    "                                \"Sample\"\n",
    "                            ).str.contains(fraction)\n",
    "                        ][assay].mean()\n",
    "                    )\n",
    "            low_fractions_values = []\n",
    "            for fraction in low_fractions:\n",
    "                if not low_fractions_df[assay].isna().all():\n",
    "                    low_fractions_values.append(\n",
    "                        low_fractions_df[\n",
    "                            low_fractions_df.index.get_level_values(\n",
    "                                \"Sample\"\n",
    "                            ).str.contains(fraction)\n",
    "                        ][assay].mean()\n",
    "                    )\n",
    "            if high_fractions_values:\n",
    "                high_fraction = min(high_fractions_values)\n",
    "            if low_fractions_values:\n",
    "                low_fraction = max(low_fractions_values)\n",
    "            if high_fraction > low_fraction:\n",
    "                correct_fractionation.append(assay)\n",
    "    return correct_fractionation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_targets(\n",
    "    correct_fractionation_uniprot_ids, cell_type_uniprot_ids, localization_uniprot_ids\n",
    "):\n",
    "    \"\"\"\n",
    "    Identifies targets that meet fractionation, cell-type specificity, and localization criteria.\n",
    "    Parameters:\n",
    "    ----------\n",
    "    'correct_fractionation_uniprot_ids': list\n",
    "        List of UniProt IDs that meet desired fractionation criteria.\n",
    "    'cell_type_uniprot_ids': list\n",
    "        List of UniProt IDs that meet desired cell-type specificity criteria.\n",
    "    'localization_uniprot_ids': list\n",
    "        List of UniProt IDs that meet desired localization criteria.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        set(correct_fractionation_uniprot_ids)\n",
    "        & set(cell_type_uniprot_ids)\n",
    "        & set(localization_uniprot_ids)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_targets_criteria(\n",
    "    assays_path,\n",
    "    uniprot_fasta_database,\n",
    "    region,\n",
    "    brain_rna_seq_path,\n",
    "    cell_type,\n",
    "    specificity_metric,\n",
    "    specificity_cutoff,\n",
    "    high_fractions,\n",
    "    low_fractions,\n",
    "    sample_health,\n",
    "    mean_median_individual,\n",
    "    raw_olink_data_file=\"none\",\n",
    "    plate_layout_dataframe=\"none\",\n",
    "    tidy_dataframe=\"none\",\n",
    "    output_directory=\"ht_output\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Identifies targets that meet specified fractionation, cell-type specificity, and localization criteria.\n",
    "    Parameters:\n",
    "    ----------\n",
    "    'assays_path': .xlsx file path\n",
    "        Path to a .xlsx file with a column containing the UniProt IDs of all the proteins in the Olink panel.\n",
    "    'uniprot_fasta_database': .gz file path\n",
    "        Path to a .gz file containing UniProt IDs and FASTA sequences.\n",
    "    'region': {'TMhelix', 'inside', 'outside', 'internal', 'external'}\n",
    "        Subcellular region requested. Options:\n",
    "          - 'TMhelix': transmembrane proteins\n",
    "          - 'inside': at least some of the protein is inside the cell/EV\n",
    "          - 'outside': at least some of the protein is outside the cell/EV\n",
    "          - 'internal': the protein is only found inside the cell, no transmembrane or outside domains\n",
    "          - 'external': the protein is only found outside the cell, no transmembrane or inside domains\n",
    "    'brain_rna_seq_path': csv file path\n",
    "        Path to the \"homo sapiens.csv\" file, downloaded from brainrnaseq.org.\n",
    "    'cell_type' : {'astrocyte', 'endothelial', 'microglia', 'oligodendrocyte', 'neuron'}\n",
    "        Cell type of interest requested. Options:\n",
    "         - 'astrocyte': mature astrocytes\n",
    "         - 'endothelial': endothelial cells\n",
    "         - 'microglia': microglia cells\n",
    "         - 'oligodendrocyte': oligodendrocytes\n",
    "         - 'neuron': neurons\n",
    "    'specificity_metric': {'tsi', 'zscore', 'spm', 'tau', 'gini', 'hg'}\n",
    "        Individualized metric of determining cell type specificity requested. Options:\n",
    "        - 'tsi': tissue specificity index\n",
    "        - 'zscore': z-score\n",
    "        - 'spm': specificity measure\n",
    "        - 'tau': tau index\n",
    "        - 'gini' : gini coefficient\n",
    "        - 'hg' : entropy of a gene's expression distribution\n",
    "    'specificity_cutoff' : numeric\n",
    "        Numeric value representing the minimum value of the second enrichment cutoff.\n",
    "    'high_fractions' : list of strings\n",
    "        Fractions that should be higher than the fractions in the list of low fractions.\n",
    "    'low_fractions' : list of strings\n",
    "        Fractions that should be lower than the fractions in the list of high fractions.\n",
    "    'sample_health' : {'all', 'ad', 'mci', 'mci_spectrum'}\n",
    "        Health of the sample requested. Options:\n",
    "            - 'healthy': only samples from healthy individuals\n",
    "            - 'all': all different health groups\n",
    "            - 'ad': samples from individuals diagnosed with Alzheimer's Disease (AD)\n",
    "            - 'mci': samples from individuals diagnosed with mild cognitive imapirment that has not yet progressed to AD\n",
    "            - 'mci_spectrum': samples from individuals diagnosed with mild cognitive impairment and samples from individuals that have been diagnosed with AD\n",
    "    'mean_median_individual' : {'mean', 'median', 'individual', 'individual_median', 'individual_mean'}\n",
    "        How the groups of samples should be analyzed. Options:\n",
    "            - 'mean': the means of each fraction should be compared against each other\n",
    "            - 'median': the medians of each fraction should be compared against each other\n",
    "            - 'individual': the fractions of each sample should be compared against each other with no aggregation/grouping\n",
    "            - 'individual_median': for each fraction, the median value of all samples will be compared\n",
    "            - 'individual_mean': for each fraction, the mean value of all samples will be compared\n",
    "        Default value: 'individual'\n",
    "    'raw_data_path': path to a .csv file, separated by semicolons\n",
    "        Path to the file containing the raw Olink data.\n",
    "    'plate_layout_dataframe': pandas.Dataframe\n",
    "        Dataframe containing information to map the SampleID of a sample to its description.\n",
    "    'tidy_dataframe' : pandas.DataFrame\n",
    "        DataFrame with one column for each assay, one row for each sample, linearized NPX as the vlaues, and the following indices:\n",
    "            - 'SampleID'\n",
    "            - 'Health'\n",
    "            - 'Sample'\n",
    "            - 'CSF_sample'\n",
    "    'output_directory': directory path\n",
    "        Path to a directory in which the localization data will be stored.\n",
    "    \"\"\"\n",
    "    if raw_olink_data_file != \"none\" and plate_layout_dataframe != \"none\":\n",
    "        tidy_dataframe = clean_up_raw_data(\n",
    "            raw_olink_data_file, plate_layout_dataframe\n",
    "        )\n",
    "\n",
    "    tidy_dataframe.dropna(axis=1, how=\"all\", inplace=True)\n",
    "\n",
    "    fasta_sequences = parse_gz_file(uniprot_fasta_database)\n",
    "    fasta_sequences.update(\n",
    "        {\n",
    "            \"NTproBNP\": \"HPLGSPGSASDLETSGLQEQRNHLQGKLSELQVEQTSLEPLQESPRPTGVWKSREVATEGIRGHRKMVLYTLRAPR\",\n",
    "            \"O43521-2\": \"MAKQPSDVSSECDREGRQLQPAERPPQLRPGAPTSLQTEPQDRSPAPMSCDKSTQTPSPPCQAFNHYLSAMASMRQAEPADMRPEIWIAQELRRIGDEFNAYYARRVFLNNYQAAEDHPRMVILRLLRYIVRLVWRMH\",\n",
    "            \"Q13114-2\": \"MESSKKMDSPGALQTNPPLKLHTDRSAGTPVFVPEQGGYKEKFVKTVEDKYKCEKCHLVLCSPKQTECGHRFCESCMAALLSSSSPKCTACQESIVKDKVFKDNCCKREILALQIYCRNESRGCAEQLMLGHLLVHLKNDCHFEELPCVRPDCKEKVLRKDLRDHVEKACKYREATCSHCKSQVPMIALQVSLLQNESVEKNKSIQSLHNQICSFEIEIERQKEMLRNNESKILHLQRVIDSQAEKLKELDKEIRPFRQNWEEADSMKSSVESLQNRVTELESVDKSAGQVARNTGLLESQLSRHDQMLSVHDIRLADMDLRFQVLETASYNGVLIWKIRDYKRRKQEAVMGKTLSLYSQPFYTGYFGYKMCARVYLNGDGMGKGTHLSLFFVIMRGEYDALLPWPFKQKVTLMLMDQGSSRRHLGDAFKPDPNSSSFKKPTGEMNIASGCPVFVAQTVLENGTYIKDDTIFIKVIVDTSDLPDP\",\n",
    "            \"O75882-2\": \"MVAAAAATEARLRRRTAATAALAGRSGGPHWDWDVTRAGRPGLGAGLRLPRLLSPPLRPRLLLLLLLLSPPLLLLLLPCEAEAAAAAAAVSGSAAAEAKECDRPCVNGGRCNPGTGQCVCPAGWVGEQCQHCGGRFRLTGSSGFVTDGPGNYKYKTKCTWLIEGQPNRIMRLRFNHFATECSWDHLYVYDGDSIYAPLVAAFSGLIVPERDGNETVPEVVATSGYALLHFFSDAAYNLTGFNITYSFDMCPNNCSGRGECKISNSSDTVECECSENWKGEACDIPHCTDNCGFPHRGICNSSDVRGCSCFSDWQGPGCSVPVPANQSFWTREEYSNLKLPRASHKAVVNGNIMWVVGGYMFNHSDYNMVLAYDLASREWLPLNRSVNNVVVRYGHSLALYKDKIYMYGGKIDSTGNVTNELRVFHIHNESWVLLTPKAKEQYAVVGHSAHIVTLKNGRVVMLVIFGHCPLYGYISNVQEYDLDKNTWSILHTQGALVQGGYGHSSVYDHRTRALYVHGGYKAFSANKYRLADDLYRYDVDTQMWTILKDSRFFRYLHTAVIVSGTMLVFGGNTHNDTSMSHGAKCFSSDFMAYDIACDRWSVLPRPDLHHDVNRFGHSAVLHNSTMYVFGGFNSLLLSDILVFTSEQCDAHRSEAACLAAGPGIRCVWNTGSSQCISWALATDEQEEKLKSECFSKRTLDHDRCDQHTDCYSCTANTNDCHWCNDHCVPRNHSCSEGQISIFRYENCPKDNPMYYCNKKTSCRSCALDQNCQWEPRNQECIALPENICGIGWHLVGNSCLKITTAKENYDNAKLFCRNHNALLASLTTQKKVEFVLKQLRIMQSSQSMSKLTLTPWVGLRKINVSYWCWEDMSPFTNSLLQWMPSEPSDAGFCGILSEPSTRGLKAATCINPLNGSVCERPANHSAKQCRTPCALRTACGDCTSGSSECMWCSNMKQCVDSNAYVASFPFGQCMEWYTMSTCPPENCSGYCTCSHCLEQPGCGWCTDPSNTGKGKCIEGSYKGPVKMPSQAPTGNFYPQPLLNSSMCLEDSRYNWSFIHCPACQCNGHSKCINQSICEKCENLTTGKHCETCISGFYGDPTNGGKCQPCKCNGHASLCNTNTGKCFCTTKGVKGDECQLCEVENRYQGNPLRGTCYYTLLIDYQFTFSLSQEDDRYYTAINFVATPDEQNRDLDMFINASKNFNLNITWAASFSAGTQAGEEMPVVSKTNIKEYKDSFSNEKFDFRNHPNITFFVYVSNFTWPIKIQVQTE\",\n",
    "            \"Q8WXW3-4\": \"MSRKISKESKKVNISSSLESEDISLETTVPTDDISSSEEREGKVRITRQLIERKELLHNIQLLKIELSQKTMMIDNLKVDYLTKIEELEEKLNDALHQKQLLTLRLDNQLAFQQKDASKYQELMKQEMETILLRQKQLEETNLQLREKAGDVRRNLRDFELTEEQYIKLKAFPEDQLSIPEYVSVRFYELVNPLRKEICELQVKKNILAEELSTNKNQLKQLTEELAAMKQILVKMHSKHSENSLLLTKTEPKHVTENQKSKTLNVPKEHEDNIFTPKPTLFTKKEAPEWSKKQKMKT\",\n",
    "        }\n",
    "    )\n",
    "    assays = pd.read_excel(assays_path)\n",
    "    assays[\"Sequence\"] = assays[\"UniProt ID\"].map(\n",
    "        lambda x: fasta_sequences.get(x, \"N/A\")\n",
    "    )\n",
    "    localization_uniprot_ids = identify_localization(assays, region, output_directory)\n",
    "\n",
    "    brain_rna_seq = map_hgnc_ids(brain_rna_seq_path)\n",
    "    cell_type_uniprot_ids = cell_type_enrichment(\n",
    "        brain_rna_seq, cell_type, specificity_metric, specificity_cutoff\n",
    "    )\n",
    "\n",
    "    correct_fractionation_uniprot_ids = analyze_fractionation(\n",
    "        tidy_dataframe,\n",
    "        high_fractions,\n",
    "        low_fractions,\n",
    "        sample_health,\n",
    "        mean_median_individual,\n",
    "    )\n",
    "\n",
    "    return identify_targets(\n",
    "        correct_fractionation_uniprot_ids,\n",
    "        cell_type_uniprot_ids,\n",
    "        localization_uniprot_ids,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSF_SAMPLES = [\n",
    "    \"SEC Fract 6 \",\n",
    "    \"SEC Fract 7\",\n",
    "    \"SEC Fract 8\",\n",
    "    \"SEC Fract 9\",\n",
    "    \"SEC Fract 10\",\n",
    "    \"SEC Fract 11\",\n",
    "    \"SEC Fract 12\",\n",
    "    \"SEC Fract 13\",\n",
    "    \"SEC Fract 14\",\n",
    "    \"SEC Fract 15\",\n",
    "]\n",
    "\n",
    "\n",
    "def graph_ht_medians(uniprot_id):\n",
    "    df = tidy_data[uniprot_id]\n",
    "    df = df[df.index.get_level_values(\"Health\") == \"Healthy\"]\n",
    "    df = df.reset_index(level=[\"SampleID\", \"Health\", \"Sample\"])\n",
    "    df[\"Sample\"] = pd.Categorical(df[\"Sample\"], categories=CSF_SAMPLES, ordered=True)\n",
    "    df_sorted = df.sort_values(\"Sample\")\n",
    "    grouped_data = [\n",
    "        group[uniprot_id].values for name, group in df_sorted.groupby(\"Sample\")\n",
    "    ]\n",
    "    plt.boxplot(grouped_data, notch=None, vert=None, patch_artist=None, widths=None)\n",
    "    plt.xlabel(\"Sample Description\")\n",
    "    plt.ylabel(\"Delta\")\n",
    "    plt.title(f\"Healthy {uniprot_id} Fractionation Pattern, HT Panel\")\n",
    "    plt.xticks(range(1, len(CSF_SAMPLES) + 1), CSF_SAMPLES)\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ratio(df):\n",
    "    peaking_fracts = df[\n",
    "        (\n",
    "            (df.index.get_level_values(\"Sample\").str.contains(\"9\"))\n",
    "            | (df.index.get_level_values(\"Sample\").str.contains(\"10\"))\n",
    "        )\n",
    "        & (df.index.get_level_values(\"Health\") == \"Healthy\")\n",
    "    ].median()\n",
    "    low_fracts = df[\n",
    "        (\n",
    "            (df.index.get_level_values(\"Sample\").str.contains(\"6\"))\n",
    "            | (df.index.get_level_values(\"Sample\").str.contains(\"7\"))\n",
    "            | (df.index.get_level_values(\"Sample\").str.contains(\"11\"))\n",
    "            | (df.index.get_level_values(\"Sample\").str.contains(\"12\"))\n",
    "            | (df.index.get_level_values(\"Sample\").str.contains(\"13\"))\n",
    "        )\n",
    "        & (df.index.get_level_values(\"Health\") == \"Healthy\")\n",
    "    ].median()\n",
    "    return peaking_fracts / low_fracts\n",
    "\n",
    "\n",
    "# ht_assay = []\n",
    "# ht_ratio = []\n",
    "\n",
    "# for assay in tidy_data.columns:\n",
    "#     df = tidy_data[\n",
    "#         (tidy_data.index.get_level_values(\"Health\") == \"Healthy\")\n",
    "#         & ~(tidy_data.index.get_level_values(\"CSF_sample\").str.contains(\"Internal\"))\n",
    "#     ][assay]\n",
    "#     ratio = find_ratio(df)\n",
    "#     ht_assay.append(assay)\n",
    "#     ht_ratio.append(ratio)\n",
    "\n",
    "# ht_fractionation = pd.DataFrame({\"ht_assay\": ht_assay, \"ht_ratio\": ht_ratio})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wyss User\\AppData\\Local\\Temp\\ipykernel_32040\\2140643050.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unique_data[\"Delta\"] = unique_data.apply(\n",
      "C:\\Users\\Wyss User\\AppData\\Local\\Temp\\ipykernel_32040\\2140643050.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unique_data.loc[:, \"Linear NPX\"] = unique_data[\"PCNormalizedNPX\"].map(lambda x: 2**x)\n"
     ]
    }
   ],
   "source": [
    "tidy_data = clean_up_raw_data(raw_data, plate_layout_path)\n",
    "graph_ht_medians(\"P10909\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wyss User\\AppData\\Local\\Temp\\ipykernel_32040\\2140643050.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unique_data[\"Delta\"] = unique_data.apply(\n",
      "C:\\Users\\Wyss User\\AppData\\Local\\Temp\\ipykernel_32040\\2140643050.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unique_data.loc[:, \"Linear NPX\"] = unique_data[\"PCNormalizedNPX\"].map(lambda x: 2**x)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'A2A288',\n",
       " 'P14317',\n",
       " 'P19838',\n",
       " 'P57796',\n",
       " 'Q12802',\n",
       " 'Q6P0N0',\n",
       " 'Q6P589',\n",
       " 'Q7Z6K4',\n",
       " 'Q9NP95',\n",
       " 'Q9Y572'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_targets_criteria(\n",
    "    assays_path = assay_list_path, \n",
    "    uniprot_fasta_database = uniprot_fasta_database, \n",
    "    region = \"internal\", \n",
    "    brain_rna_seq_path = brain_rna_seq_path,\n",
    "    cell_type = \"microglia\", \n",
    "    specificity_metric = \"tau\", \n",
    "    specificity_cutoff = 0.75,\n",
    "    high_fractions = ['9', '10'], \n",
    "    low_fractions = ['7', '11', '12', '13'], \n",
    "    sample_health = 'healthy', \n",
    "    mean_median_individual = 'individual_median',\n",
    "    raw_olink_data_file = raw_data,\n",
    "    plate_layout_dataframe = plate_layout_path\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
